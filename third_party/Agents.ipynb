{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5170bf5b",
   "metadata": {},
   "source": [
    "# Agents - Make OpenAI Do Things For you"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b21f6",
   "metadata": {},
   "source": [
    "This tutorial was obtained from: https://github.com/gkamradt/langchain-tutorials/blob/main/agents/Agents.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9faa06",
   "metadata": {},
   "source": [
    "*[Source](https://langchain.readthedocs.io/en/latest/modules/agents/getting_started.html)*\n",
    "* **Agent** - Agents use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output, or returning to the user.\n",
    "\n",
    "Parameters when creating an agent:\n",
    "* **Tool:** A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains. The interface for a tool is currently a function that is expected to have a string as an input, with a string as an output.\n",
    "* **LLM:** The language model powering the agent.\n",
    "* **Agent:** The agent to use. This should be a string that references a support agent class. Because this notebook focuses on the simplest, highest level API, this only covers using the standard supported agents. If you want to implement a custom agent, see the documentation for custom agents (coming soon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3081aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in /usr/local/lib/python3.10/dist-packages (2.4.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (1.26.15)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f247903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd3670a",
   "metadata": {},
   "source": [
    "### List of Tools\n",
    "1. **python_repl -** A Python shell. Use this to execute python commands. Input should be a valid python command. If you expect output it should be printed out.\n",
    "2. **serpapi [Complete] -** A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
    "3. **wolfram-alpha [Complete] -** A wolfram alpha search engine. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query.\n",
    "4. **requests -** A portal to the internet. Use this when you need to get specific content from a site. Input should be a specific url, and the output will be all the text on that page.\n",
    "5. **terminal -** Executes commands in a terminal. Input should be valid commands, and the output will be any output from running that command.\n",
    "6. **pal-math -** A language model that is excellent at solving complex word math problems. Input should be a fully worded hard word math problem.\n",
    "7. **pal-colored-objects -** A language model that is wonderful at reasoning about position and the color attributes of objects. Input should be a fully worded hard reasoning problem. Make sure to include all information about the objects AND the final question you want to answer.\n",
    "8. **llm-math -** Useful for when you need to answer questions about math.\n",
    "9. **open-meteo-api -** Useful for when you want to get weather information from the OpenMeteo API. The input should be a question in natural language that this API can answer.\n",
    "10. **news-api -** Use this when you want to get information about the top headlines of current news stories. The input should be a question in natural language that this API can answer.\n",
    "11. **tmdb-api -** Useful for when you want to get information from The Movie Database. The input should be a question in natural language that this API can answer.\n",
    "12. **google-search -** A wrapper around Google Search. Useful for when you need to answer questions about current events. Input should be a search query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83032dcf",
   "metadata": {},
   "source": [
    "### 2. SERP API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c90ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "# import os\n",
    "# os.environ['OPENAI_API_KEY'] = \"...\"\n",
    "# os.environ['SERPAPI_API_KEY'] = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0f2fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f26a0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = [\"serpapi\"]\n",
    "tools = load_tools(tool_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8a35518",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True, tracing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "829a2d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should research this online.\n",
      "Action: Search\n",
      "Action Input: \"LangChain\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This looks like the answer I'm looking for.\n",
      "Final Answer: LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only leverage the power of language models, but also the power of the community to create and share data.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only leverage the power of language models, but also the power of the community to create and share data.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is LangChain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4cc45f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out who the CEO of Pipe is\n",
      "Action: Search\n",
      "Action Input: \"CEO of Pipe\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLuke Voiles\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Luke Voiles is the CEO of Pipe.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Luke Voiles is the CEO of Pipe.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input should be a search query.\n",
    "agent.run(\"who is the ceo of pipe?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1869cabc",
   "metadata": {},
   "source": [
    "### 3. Wolfram Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fd02098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "# import os\n",
    "# pip install wolframalpha\n",
    "# os.environ['OPENAI_API_KEY'] = \"...\"\n",
    "# os.environ['WOLFRAM_ALPHA_APPID'] = \"..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a96dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ba4200b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for WolframAlphaAPIWrapper\n__root__\n  Did not find wolfram_alpha_appid, please add an environment variable `WOLFRAM_ALPHA_APPID` which contains it, or pass  `wolfram_alpha_appid` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tool_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwolfram-alpha\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m tools \u001b[38;5;241m=\u001b[39m \u001b[43mload_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/load_tools.py:300\u001b[0m, in \u001b[0;36mload_tools\u001b[0;34m(tool_names, llm, callback_manager, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m _get_tool_func, extra_keys \u001b[38;5;241m=\u001b[39m _EXTRA_OPTIONAL_TOOLS[name]\n\u001b[1;32m    299\u001b[0m sub_kwargs \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m extra_keys \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs}\n\u001b[0;32m--> 300\u001b[0m tool \u001b[38;5;241m=\u001b[39m \u001b[43m_get_tool_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msub_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callback_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m     tool\u001b[38;5;241m.\u001b[39mcallback_manager \u001b[38;5;241m=\u001b[39m callback_manager\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/load_tools.py:167\u001b[0m, in \u001b[0;36m_get_wolfram_alpha\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_wolfram_alpha\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseTool:\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m WolframAlphaQueryRun(api_wrapper\u001b[38;5;241m=\u001b[39m\u001b[43mWolframAlphaAPIWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for WolframAlphaAPIWrapper\n__root__\n  Did not find wolfram_alpha_appid, please add an environment variable `WOLFRAM_ALPHA_APPID` which contains it, or pass  `wolfram_alpha_appid` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "tool_names = [\"wolfram-alpha\"]\n",
    "tools = load_tools(tool_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4716e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "89e0d255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The asthenosphere is the lower layer of the crust.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input should be a search query.\n",
    "\n",
    "agent.run(\"What is the asthenosphere?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c98c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
